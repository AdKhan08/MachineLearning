{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aw8-YPlNw_iQ"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-cEcPsdxMAA",
    "outputId": "6f8a8c93-ac81-4ece-e7b4-f5e28369b934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification dataset shape: (45000, 14)\n",
      "\n",
      "First few rows:\n",
      "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
      "0        22.0        female           Master        71948.0               0   \n",
      "1        21.0        female      High School        12282.0               0   \n",
      "2        25.0        female      High School        12438.0               3   \n",
      "3        23.0        female         Bachelor        79753.0               0   \n",
      "4        24.0          male           Master        66135.0               1   \n",
      "\n",
      "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
      "0                  RENT    35000.0    PERSONAL          16.02   \n",
      "1                   OWN     1000.0   EDUCATION          11.14   \n",
      "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
      "3                  RENT    35000.0     MEDICAL          15.23   \n",
      "4                  RENT    35000.0     MEDICAL          14.27   \n",
      "\n",
      "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
      "0                 0.49                         3.0           561   \n",
      "1                 0.08                         2.0           504   \n",
      "2                 0.44                         3.0           635   \n",
      "3                 0.44                         2.0           675   \n",
      "4                 0.53                         4.0           586   \n",
      "\n",
      "  previous_loan_defaults_on_file  loan_status  \n",
      "0                             No            1  \n",
      "1                            Yes            0  \n",
      "2                             No            1  \n",
      "3                             No            1  \n",
      "4                             No            1  \n",
      "\n",
      "Missing values in classification dataset:\n",
      "person_age                        0\n",
      "person_gender                     0\n",
      "person_education                  0\n",
      "person_income                     0\n",
      "person_emp_exp                    0\n",
      "person_home_ownership             0\n",
      "loan_amnt                         0\n",
      "loan_intent                       0\n",
      "loan_int_rate                     0\n",
      "loan_percent_income               0\n",
      "cb_person_cred_hist_length        0\n",
      "credit_score                      0\n",
      "previous_loan_defaults_on_file    0\n",
      "loan_status                       0\n",
      "dtype: int64\n",
      "\n",
      "Training set shape: (36000, 22), Test set shape: (9000, 22)\n"
     ]
    }
   ],
   "source": [
    "# Load classification dataset\n",
    "loan_data = pd.read_csv('loan_data.csv')\n",
    "\n",
    "# Display dataset info\n",
    "print(\"Classification dataset shape:\", loan_data.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(loan_data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in classification dataset:\")\n",
    "print(loan_data.isnull().sum())\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "loan_data_encoded = pd.get_dummies(loan_data, drop_first=True)\n",
    "\n",
    "# Define features and target\n",
    "X = loan_data_encoded.drop('loan_status', axis=1)\n",
    "y = loan_data_encoded['loan_status']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"\\nTraining set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3FL32RTyQfL",
    "outputId": "2822154a-dca0-4ad3-c30d-5add340b83e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 1: Classification - Original Data Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Table 1: Original data with 6 classifiers\n",
    "print(\"\\nTable 1: Classification - Original Data Metrics\")\n",
    "classification_table1 = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    metrics = evaluate_classifier(clf, X_train, X_test, y_train, y_test)\n",
    "    classification_table1[name] = metrics\n",
    "\n",
    "# Convert to DataFrame\n",
    "classification_table1_df = pd.DataFrame(classification_table1).T\n",
    "print(classification_table1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "te-OeXc7yUcz",
    "outputId": "6ae63a41-de78-48c2-a21b-e873c7062aff"
   },
   "outputs": [],
   "source": [
    "# Apply different scaling techniques\n",
    "scaler_methods = {\n",
    "    'L1 Normalization': Normalizer(norm='l1'),\n",
    "    'L2 Normalization': Normalizer(norm='l2'),\n",
    "    'Min-Max Scaling': MinMaxScaler(),\n",
    "    'Standard Scaling': StandardScaler()\n",
    "}\n",
    "\n",
    "print(\"\\nTable 2: Classification - After Scaling Metrics\")\n",
    "classification_table2 = {}\n",
    "\n",
    "for scaler_name, scaler in scaler_methods.items():\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        metrics = evaluate_classifier(clf, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        model_scaler = f\"{clf_name} with {scaler_name}\"\n",
    "        classification_table2[model_scaler] = metrics\n",
    "\n",
    "# Convert to DataFrame\n",
    "classification_table2_df = pd.DataFrame(classification_table2).T\n",
    "print(classification_table2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r205SnqSyX2K"
   },
   "outputs": [],
   "source": [
    "# Define reduced parameter grids for GridSearchCV (fewer combinations for faster execution)\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1],  # Reduced options\n",
    "        'solver': ['liblinear']  # Just one solver\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [1],  # Single most common value\n",
    "        'kernel': ['linear']  # Linear kernel is faster than RBF\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50],  # Reduced options\n",
    "        'max_depth': [10]  # Single value\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50],  # Fewer trees\n",
    "        'learning_rate': [0.1]  # Higher learning rate converges faster\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'n_neighbors': [5],  # Only middle value\n",
    "        'weights': ['uniform']  # Just one option\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [10],  # Single value\n",
    "        'min_samples_split': [2]  # Just one option\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function for GridSearchCV with 10-fold CV but with performance optimizations\n",
    "def perform_grid_search(clf, param_grid, X, y):\n",
    "    # Reduce dataset size for faster processing\n",
    "    if len(X) > 10000:  # Only sample if dataset is large\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_sample, _, y_sample, _ = train_test_split(X, y,\n",
    "                                                  train_size=0.3,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y)\n",
    "    else:\n",
    "        X_sample, y_sample = X, y\n",
    "\n",
    "    # Keep 10-fold CV as requested but add parallel processing\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=cv, scoring='accuracy',\n",
    "                              n_jobs=-1,  # Use all CPU cores\n",
    "                              verbose=1)  # Show progress\n",
    "\n",
    "    print(f\"Starting GridSearchCV on {len(X_sample)} samples\")\n",
    "    grid_search.fit(X_sample, y_sample)\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Fit the best model on the full training data\n",
    "    if len(X) > 10000:\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        best_clf.fit(X, y)\n",
    "        return best_clf\n",
    "    else:\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nTable 3: Classification - After GridSearchCV and 10-fold Cross-Validation\")\n",
    "classification_table3 = {}\n",
    "\n",
    "# Add import for time tracking\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nPerforming GridSearchCV for {clf_name}...\")\n",
    "    clf_start = time.time()\n",
    "    best_clf = perform_grid_search(clf, param_grids[clf_name], X_train, y_train)\n",
    "    metrics = evaluate_classifier(best_clf, X_train, X_test, y_train, y_test)\n",
    "    classification_table3[clf_name] = metrics\n",
    "    print(f\"Completed {clf_name} in {time.time() - clf_start:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nTotal GridSearchCV time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "classification_table3_df = pd.DataFrame(classification_table3).T\n",
    "print(\"\\nTable 3: Classification Results After Optimization\")\n",
    "print(classification_table3_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CH_AgO6n14UT"
   },
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"\\nNumber of components after PCA: {X_train_pca.shape[1]}\")\n",
    "\n",
    "print(\"\\nTable 4: Classification - After PCA\")\n",
    "classification_table4 = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    metrics = evaluate_classifier(clf, X_train_pca, X_test_pca, y_train, y_test)\n",
    "    classification_table4[name] = metrics\n",
    "\n",
    "# Convert to DataFrame\n",
    "classification_table4_df = pd.DataFrame(classification_table4).T\n",
    "print(classification_table4_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5h0v8O_19Fq"
   },
   "outputs": [],
   "source": [
    "# Load regression dataset\n",
    "real_estate = pd.read_csv('Real estate.csv')\n",
    "\n",
    "# Display dataset info\n",
    "print(\"\\nRegression dataset shape:\", real_estate.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(real_estate.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in regression dataset:\")\n",
    "print(real_estate.isnull().sum())\n",
    "\n",
    "# Define features and target\n",
    "X_reg = real_estate.drop(['No', 'Y house price of unit area'], axis=1)\n",
    "y_reg = real_estate['Y house price of unit area']\n",
    "\n",
    "# Split data\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"\\nTraining set shape: {X_reg_train.shape}, Test set shape: {X_reg_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOmIVUjK1-BO"
   },
   "outputs": [],
   "source": [
    "# Define regressors\n",
    "regressors = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# Function to evaluate regressors\n",
    "def evaluate_regressor(reg, X_train, X_test, y_train, y_test):\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'R² Score': r2_score(y_test, y_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YuhzUAl2GAQ"
   },
   "outputs": [],
   "source": [
    "# Table 1: Original data with 6 regressors\n",
    "print(\"\\nTable 1: Regression - Original Data Metrics\")\n",
    "regression_table1 = {}\n",
    "\n",
    "for name, reg in regressors.items():\n",
    "    metrics = evaluate_regressor(reg, X_reg_train, X_reg_test, y_reg_train, y_reg_test)\n",
    "    regression_table1[name] = metrics\n",
    "\n",
    "# Convert to DataFrame\n",
    "regression_table1_df = pd.DataFrame(regression_table1).T\n",
    "print(regression_table1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ua6PPTO02Iig"
   },
   "outputs": [],
   "source": [
    "# Define simplified parameter grids for regressors (fewer combinations for faster execution)\n",
    "reg_param_grids = {\n",
    "    'Linear Regression': {\n",
    "        'fit_intercept': [True]  # Reduced to just default option\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': [0.1, 1],  # Reduced options\n",
    "        'solver': ['auto']  # Only the default solver\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.1, 1],  # Reduced options\n",
    "        'selection': ['cyclic']  # Only the default option\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50],  # Single value\n",
    "        'max_depth': [10]  # Single value\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50],  # Fewer trees\n",
    "        'learning_rate': [0.1]  # Higher learning rate\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [1],  # Single value\n",
    "        'kernel': ['linear']  # Linear is faster than RBF\n",
    "    }\n",
    "}\n",
    "\n",
    "# Optimized function for GridSearchCV with 10-fold CV for regression\n",
    "def perform_grid_search_reg(reg, param_grid, X, y):\n",
    "    # Sample data if it's large to speed up processing\n",
    "    if len(X) > 1000:  # Threshold for sampling\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_sample, _, y_sample, _ = train_test_split(X, y,\n",
    "                                                   train_size=0.3,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=None)\n",
    "        print(f\"Sampled {len(X_sample)} from {len(X)} records for faster processing\")\n",
    "    else:\n",
    "        X_sample, y_sample = X, y\n",
    "\n",
    "    # Keep 10-fold CV as requested but add performance optimizations\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(reg, param_grid, cv=cv,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              n_jobs=-1,  # Use all CPU cores\n",
    "                              verbose=1)  # Show progress\n",
    "\n",
    "    # Track execution time\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    grid_search.fit(X_sample, y_sample)\n",
    "\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best MSE: {-grid_search.best_score_:.4f}\")\n",
    "    print(f\"GridSearch completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Refit the best model on the full dataset if we sampled\n",
    "    if len(X) > 1000:\n",
    "        print(\"Refitting best model on full training data...\")\n",
    "        best_reg = grid_search.best_estimator_\n",
    "        best_reg.fit(X, y)\n",
    "        return best_reg\n",
    "    else:\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nTable 2: Regression - After GridSearchCV and 10-fold Cross-Validation\")\n",
    "regression_table2 = {}\n",
    "\n",
    "# Track total execution time\n",
    "import time\n",
    "total_start_time = time.time()\n",
    "\n",
    "for reg_name, reg in regressors.items():\n",
    "    print(f\"\\nPerforming GridSearchCV for {reg_name}...\")\n",
    "    best_reg = perform_grid_search_reg(reg, reg_param_grids[reg_name], X_reg_train, y_reg_train)\n",
    "    metrics = evaluate_regressor(best_reg, X_reg_train, X_reg_test, y_reg_train, y_reg_test)\n",
    "    regression_table2[reg_name] = metrics\n",
    "\n",
    "print(f\"\\nTotal execution time: {time.time() - total_start_time:.2f} seconds\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "regression_table2_df = pd.DataFrame(regression_table2).T\n",
    "print(\"\\nTable 2: Regression Results After Optimization\")\n",
    "print(regression_table2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yLNckQP2NVt"
   },
   "outputs": [],
   "source": [
    "# Plot classification results\n",
    "plt.figure(figsize=(12, 6))\n",
    "classification_table1_df['Accuracy'].plot(kind='bar', color='skyblue')\n",
    "plt.title('Classification Models Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot regression results\n",
    "plt.figure(figsize=(12, 6))\n",
    "regression_table1_df['R² Score'].plot(kind='bar', color='lightgreen')\n",
    "plt.title('Regression Models R² Score')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
